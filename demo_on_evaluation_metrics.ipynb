{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo on Evaluation Metrics for Regression and Classification Modeling\n",
    "\n",
    "- [Part I. Regression Metrics](#reg)\n",
    "- [Part II. Classification Metrics](#cls)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reg'></a>\n",
    "## Part I. Regression Metrics\n",
    "\n",
    "There are three common metrics on regression models, i.e.,  \n",
    "- **Mean of Absolute Errors**\n",
    "- **Mean of Squared Errors**\n",
    "- **R_2 Score**\n",
    "\n",
    "sklearn has all of them:\n",
    "\n",
    "`from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reg_content'></a>\n",
    "For the demonstration purpose, I will use the built-in `Boston Housing dataset` in sklearn. Follow the **10 STEPS** below.\n",
    "\n",
    "- [STEP 1: Import the related packages and dataset.](#reg_step1)\n",
    "- [STEP 2: Import regression modeling packages and evaluation metrics packages from sklearn.](#reg_step2)\n",
    "- [STEP 3: Instantiate the regressors](#reg_step3)\n",
    "- [STEP 4: Fit the instantiated models on the training data.](#reg_step4)\n",
    "- [STEP 5: Use the fitted models to predict.](#reg_step5)\n",
    "- [STEP 6: Self-define the calculation of r2, mse, mae.](#reg_step5)\n",
    "- [STEP 7: Compare the results between self-defined functions and sklearn built-in methods.](#reg_step7)\n",
    "- [STEP 8: Print out and compare all the results to see which model did the best.](#reg_step8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reg_step1'></a>\n",
    "**STEP 1: Read in the dataset and set up the training and testing data that will be used for the rest of this task.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "boston = load_boston()\n",
    "y = boston.target\n",
    "X = boston.data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get to a little bit know about the dataset.\n",
    "print(boston['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back](#reg_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reg_step2'></a>\n",
    "**STEP 2: Import FOUR packages for regression modeling from sklearn**\n",
    "\n",
    "Here, we choose \n",
    "- `RandomForestRegressor` and `AdaBoostRegressor` in `ensemble` methods; \n",
    "- `LinearRegression`\n",
    "- `DecisionTreeRegressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice: be sure to choose the regressor version (not the classifier version)\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Import the built-in metrics for regression models in sklearn\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back](#reg_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reg_step3'></a>\n",
    "**STEP 3: Instantiate each of the four regressors and use the defaults for all the hyperparameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_mod = DecisionTreeRegressor()\n",
    "rf_mod = RandomForestRegressor()\n",
    "ada_mod = AdaBoostRegressor()\n",
    "reg_mod = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reg_step4'></a>\n",
    "**STEP 4: Fit the instantiated models on the training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_mod.fit(X_train, y_train)\n",
    "rf_mod.fit(X_train, y_train)\n",
    "ada_mod.fit(X_train, y_train)\n",
    "reg_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reg_step5'></a>\n",
    "**STEP 5: Use each of the fitted models to predict on the testing data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_tree = tree_mod.predict(X_test) \n",
    "preds_rf = rf_mod.predict(X_test)\n",
    "preds_ada = ada_mod.predict(X_test)\n",
    "preds_reg = reg_mod.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back](#reg_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reg_step6'></a>\n",
    "**STEP 6: Self-define these THREE metrics to understand how they will be calculated in sklearn under the hood.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2 score definition\n",
    "def r2(actual, preds):\n",
    "    '''\n",
    "    INPUT:\n",
    "    actual - numpy array or pd series of actual y values\n",
    "    preds - numpy array or pd series of predicted y values\n",
    "    OUTPUT:\n",
    "    returns the r-squared score as a float\n",
    "    '''\n",
    "    sse = np.sum((actual-preds)**2)\n",
    "    sst = np.sum((actual-np.mean(actual))**2)\n",
    "    return 1 - sse/sst\n",
    "\n",
    "# Check solution matches sklearn\n",
    "print(r2(y_test, preds_tree))\n",
    "print(r2_score(y_test, preds_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse (mean squared errors) definition\n",
    "def mse(actual, preds):\n",
    "    '''\n",
    "    INPUT:\n",
    "    actual - numpy array or pd series of actual y values\n",
    "    preds - numpy array or pd series of predicted y values\n",
    "    OUTPUT:\n",
    "    returns the mean squared error as a float\n",
    "    '''\n",
    "    \n",
    "    return np.mean((actual - preds)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mae (mean absolute errors) definition\n",
    "def mae(actual, preds):\n",
    "    '''\n",
    "    INPUT:\n",
    "    actual - numpy array or pd series of actual y values\n",
    "    preds - numpy array or pd series of predicted y values\n",
    "    OUTPUT:\n",
    "    returns the mean absolute error as a float\n",
    "    '''\n",
    "    \n",
    "    return np.mean(np.abs((actual - preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back](#reg_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reg_step7'></a>\n",
    "**STEP 7: Check the results above with the built-in results from sklearn. Take Decision Tree model for an example.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Built-in</th>\n",
       "      <th>Self-defined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2 score</th>\n",
       "      <td>0.749784</td>\n",
       "      <td>0.749784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean squared error</th>\n",
       "      <td>18.935988</td>\n",
       "      <td>18.935988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean absolute error</th>\n",
       "      <td>2.956287</td>\n",
       "      <td>2.956287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Built-in  Self-defined\n",
       "r2 score              0.749784      0.749784\n",
       "mean squared error   18.935988     18.935988\n",
       "mean absolute error   2.956287      2.956287"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Built-in':[r2_score(y_test, preds_tree), mean_squared_error(y_test, preds_tree), mean_absolute_error(y_test, preds_tree)], \\\n",
    "       'Self-defined': [r2(y_test, preds_tree), mse(y_test, preds_tree), mae(y_test, preds_tree)]}\n",
    "results = pd.DataFrame(data, index=['r2 score', 'mean squared error', 'mean absolute error'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back](#reg_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reg_step8'></a>\n",
    "**STEP 8: Use the built-in methods to print out all the results to see which model did the best.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_true, preds, model_name=None):\n",
    "    '''\n",
    "    INPUT:\n",
    "    y_true - the y values that are actually true in the dataset (numpy array or pandas series)\n",
    "    preds - the predictions for those values from some model (numpy array or pandas series)\n",
    "    model_name - (str - optional) a name associated with the model if you would like to add it to the print statements \n",
    "    \n",
    "    OUTPUT:\n",
    "    None - prints the mse, mae, r2\n",
    "    '''\n",
    "    if model_name == None:\n",
    "        print('Mean Squared Error: ', format(mean_squared_error(y_true, preds)))\n",
    "        print('Mean Absolute Error: ', format(mean_absolute_error(y_true, preds)))\n",
    "        print('R2 Score: ', format(r2_score(y_true, preds)))\n",
    "        print('\\n\\n')\n",
    "    \n",
    "    else:\n",
    "        print('Mean Squared Error ' + model_name + ' :' , format(mean_squared_error(y_true, preds)))\n",
    "        print('Mean Absolute Error ' + model_name + ' :', format(mean_absolute_error(y_true, preds)))\n",
    "        print('R2 Score ' + model_name + ' :', format(r2_score(y_true, preds)))\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error tree : 18.9359880239521\n",
      "Mean Absolute Error tree : 2.9562874251497004\n",
      "R2 Score tree : 0.749783810077857\n",
      "\n",
      "\n",
      "\n",
      "Mean Squared Error random forest : 10.21522224550898\n",
      "Mean Absolute Error random forest : 2.168616766467066\n",
      "R2 Score random forest : 0.8650181872608877\n",
      "\n",
      "\n",
      "\n",
      "Mean Squared Error adaboost : 15.74723290871108\n",
      "Mean Absolute Error adaboost : 2.772526116068805\n",
      "R2 Score adaboost : 0.7919193540231275\n",
      "\n",
      "\n",
      "\n",
      "Mean Squared Error linear reg : 20.72402343733974\n",
      "Mean Absolute Error linear reg : 3.1482557548168217\n",
      "R2 Score linear reg : 0.7261570836552478\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print Decision Tree scores\n",
    "print_metrics(y_test, preds_tree, 'tree')\n",
    "\n",
    "# Print Random Forest scores\n",
    "print_metrics(y_test, preds_rf, 'random forest')\n",
    "\n",
    "# Print AdaBoost scores\n",
    "print_metrics(y_test, preds_ada, 'adaboost')\n",
    "\n",
    "# Linear Regression scores\n",
    "print_metrics(y_test, preds_reg, 'linear reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>As we can see from above, the <font color='green'>**random forest**</font> model was the best in terms of all the metrics in this case. (i.e. the smallest of `mse` and `mae`, and largest `r2 score`.)</font>\n",
    "\n",
    "[Back](#reg_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cls'></a>\n",
    "## Part II. Classification Metrics\n",
    "\n",
    "This part will dig into a number of techniques used to understand how well the **classification model** is performing. Namely use four metrics:  \n",
    "- **accuracy_score**\n",
    "- **precision_score**\n",
    "- **recall_score**\n",
    "- **f1_score**\n",
    "\n",
    "The dataset for demo is the `spam` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 1: Import packages and prepare the data, and then instantiate a number of different models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('projects_on_GitHub/Machine_learning/Evaluation_Metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "%matplotlib inline\n",
    "# Read in our dataset\n",
    "df = pd.read_table('smsspamcollection/SMSSpamCollection',\n",
    "                   sep='\\t', \n",
    "                   header=None, \n",
    "                   names=['label', 'sms_message'])\n",
    "\n",
    "# Fix our response value\n",
    "df['label'] = df.label.map({'ham':0, 'spam':1})\n",
    "\n",
    "# Split our dataset into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['sms_message'], \n",
    "                                                    df['label'], \n",
    "                                                    random_state=1)\n",
    "\n",
    "# Instantiate the CountVectorizer method\n",
    "count_vector = CountVectorizer()\n",
    "\n",
    "# Fit the training data and then return the matrix\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "\n",
    "# Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()\n",
    "testing_data = count_vector.transform(X_test)\n",
    "\n",
    "# Instantiate a number of our models\n",
    "naive_bayes = MultinomialNB()\n",
    "bag_mod = BaggingClassifier(n_estimators=200)\n",
    "rf_mod = RandomForestClassifier(n_estimators=200)\n",
    "ada_mod = AdaBoostClassifier(n_estimators=300, learning_rate=0.2)\n",
    "svm_mod = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 2: Fit these models on the training dataset and predict on the testing dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit each of the 4 models\n",
    "# This might take some time to run\n",
    "naive_bayes.fit(training_data, y_train)\n",
    "bag_mod.fit(training_data, y_train)\n",
    "rf_mod.fit(training_data, y_train)\n",
    "ada_mod.fit(training_data, y_train)\n",
    "svm_mod.fit(training_data, y_train)\n",
    "\n",
    "# Make predictions using each of these models\n",
    "preds_nb = naive_bayes.predict(testing_data)\n",
    "preds_bag = bag_mod.predict(testing_data)\n",
    "preds_rf = rf_mod.predict(testing_data)\n",
    "preds_ada = ada_mod.predict(testing_data)\n",
    "preds_svm = svm_mod.predict(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand how each metric was calculated under tbe hood of `sklearn`, the following cells will self-define some functions for calculating these metrics with a single model (e.g. naive bayes model), and at the end of this part we are able to choose models that are best based on a particular metric.\n",
    "\n",
    "**STEP 3: Self-define the four metrics for classification models, i.e., `accuracy score`, `precision score`, `recall score`, and `f1 score`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
